Lecture 2

Scraping
* Access HTML code in Chrome: F12
* Useful tags: heading <h1></h1> ... <h6></h6>, paragraph <p></p>, line break <br>,
link with attribute <a href="http://www.example.com/">An example link</a>
* Useful libraries in Python: urllib, beautifulsoup, pattern,soupy, LXML
* Python scraping tutorial: htts://github.com/kjam/python-web-scraping-tutorial

Lecture 3 - EDA (Really good lecture!)
* 1. Ask questions, 2. Get the data, 3. Explore the data, 4. Model the data, 5. Communicate and visualize the data
* If a plot doesn't start at zero, point it out.
* Don't use graphics that you don't need.
* Charts for comparison: Bar charts, line plots (bars for discrete time data),
  stacked bar charts (proportions).
* A pie chart is not as effective as a bar chart.
* Distribution plots: Histogram (play with bin size), density plot (continuous) .
* Design  (of visualizations) is an exercise of creating many alternatives quickly.
* Difference bar graph shows the difference between before and after.
* Sometimes raw numbers is best to communicate results.
* Good measures: length, position. Bad: color, shape, slope, angle, area, 
  and intensity.
* Quantitative data: Position (point), length (bar), slope (line), angle (pie).
* Ordered data: Area, Intensity
* Categories: Color, Shape
* Do not use more than 5-8 colors at once.
* Do not use rainbow color maps.
* Instead use greyscale color map with color to highlight data.
* For good color choices, go to Colorbrewer.

Lecture 4 - SQL, Relational Model/Grammar of Data
* Recommended database: Postgres, which is open source and supports both relational data and JSON
* A key should be unique, like an id. An integer is usually suitable.
* Nice table with translations: Verb, dplyr, pandas, SQL

Lecture 5 - Statistical models
* Exponential distribution, memoryless property: f(x) = lambda*exp(-lambda*x), x > 0
* Parametric distributions are connected in some ways.
* Poisson distribution for counts of rare events.
* 68% chance of being inside +-1 sigma if normally distributed
* 95% chance of being inside +-2 sigma if normally distributed
* 99% chance of being inside +-3 sigma if normally distributed
* It is often the case that if you have positive data and take the log, it becomes more normal/nicer to work with.
* Log-normal distribution: Becomes normally distributed if log is applied on it.

Lecture 6 - Communication and Storytelling (Good lecture on how to present your results orally and written)
* Giving a speech, two obvious questions to answer: 1. What is the primary goals?, 2. Who cares?
* Choose and use notation carefully
* Include a simple, but memorable example, like Linda the bank teller
* Tell a story with a beginning, a middle, and an end. E.g. ants.
  * Introduce interesting characters
  * Put them in a predicament
  * Resolve the predicament
  * Leave room for sequels! That is: limitations and future work.
* If you give a talk, show a lot of visualizations
* Whenever you can tell a story with your data, do that!
* Who is your audience, what questions are you answering, why should the audience care, what are the major insights and surprises.
* Know your audience:
  * What do they know?
  * What motivates them, what do they desire?
  * What experiences do you share, what are common goals?
  * What insights can you give them? What tools and "magical gifts"?
* Don't make your audience think too much. Make the main message very explicit!
* Continue at 49:41




